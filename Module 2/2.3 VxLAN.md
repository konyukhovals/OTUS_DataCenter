![image](https://github.com/user-attachments/assets/7e95905c-7ae1-40ad-99d6-a6afe7f26292)

![image](https://github.com/user-attachments/assets/474fc89e-cf19-40f4-93e7-9fe12a1118c5)

VXLAN (Virtual eXtensible LAN) — это технология оверлейной (overlay) сетевой виртуализации, которая позволяет создавать поверх существующей L3-сети логические L2-сегменты. Проще говоря, VXLAN «транспортирует» фреймы второго уровня (Ethernet) внутри пакетов IP (UDP), обеспечивая изоляцию трафика на уровне виртуальных сетей (VNI — VXLAN Network Identifier). Это решение получило широкое распространение в современных центрах обработки данных (ЦОД) для обеспечения гибкости в развертывании сетевой инфраструктуры и «растягивания» L2-сегментов между разными частями сети.

## Для чего нужен VXLAN в разрезе ЦОД

* Увеличение масштаба (Scaling). Стандартный VLAN имеет лимит в 4096 (12-битное поле VLAN ID), и в больших ЦОДовских сетях этого уже недостаточно. VXLAN использует 24-битный VNI (VXLAN Network Identifier), что даёт до 16 миллионов изолированных сетевых сегментов.
* Гибкость и «растяжение» сети. Часто возникает потребность объединить серверы или виртуальные машины (ВМ), которые находятся в разных физических частях сети, в один логический L2-сегмент (например, в рамках одной tenant-сети). VXLAN позволяет это сделать поверх IP-сети, не меняя основную топологию.
* Проще масштабировать и управлять. Сеть остается базово маршрутизируемой (Layer 3), а поверх неё создаются логические L2 сегменты. Это позволяет использовать классические преимущества маршрутизации (ECMP, отказоустойчивость на уровне IP и т.д.), а поверх организовывать «плоскую» сеть для виртуальных машин или контейнеров.
* Изоляция арендаторов. В ЦОД с несколькими «tenant’-ами» удобно изолировать трафик разных арендаторов по разным VNI. Трафик проходит поверх общей IP-сети, но при этом каждый арендатор видит только свою среду на втором уровне.

## Отличие VXLAN от EVPN
Зачастую эти понятия упоминают вместе, что может вносить путаницу:
* VXLAN — это протокол инкапсуляции «Ethernet поверх UDP/IP», то есть решение чисто канального (Data Plane) уровня: как «упаковать» и перенести L2-фрейм через L3.
* EVPN (Ethernet VPN) — это протокол маршрутизации и распространения L2/L3-информации (Control Plane) с помощью BGP. EVPN решает задачу обмена MAC-адресами (а также IP-префиксами, если нужно) между “узлами” сети, которая развёрнута на VXLAN.
* * EVPN может управлять тем, куда следует отправлять трафик для конкретного MAC-адреса/IP-префикса, какие узлы являются активными шлюзами и т.д.
* * EVPN даёт возможность построить более масштабируемую и динамическую систему, где устройства-Leaf и Spine (или маршрутизаторы, поддерживающие VXLAN) автоматически обмениваются информацией о «находящихся» у них хостах на L2-уровне.

Иными словами:
* VXLAN — это транспортная часть (энкапсуляция).
* EVPN — это «мозг», который позволяет динамически создавать и поддерживать эти виртуальные сети, синхронизировать информацию о MAC/IP и маршрутах.

При использовании только VXLAN (без EVPN) приходится вручную управлять многими аспектами — например, прописывать статические «флуды и мультикасты» (или unicast peer-адреса VTEP’ов), заниматься ARP/ND-проксированием и т.д. При VXLAN c EVPN всё это автоматизируется через BGP.

## Пример настройки VXLAN

В качестве примера рассмотрим упрощённую схему настройки VXLAN на сетевых коммутаторах (либо с использованием Linux-серверов в качестве VTEP).

1. Пример на Cisco Nexus (без EVPN)
Предположим, у нас есть два коммутатора Nexus, которые должны «растянуть» VLAN 10 через IP-сеть с помощью VXLAN. Мы используем multicast-группу для «flood & learn».
На коммутаторе Nexus A:

```
! Включаем поддержку функций VXLAN
feature nv overlay
feature vn-segment-vlan-based

! Создаём NVE интерфейс (Network Virtualization Edge — VXLAN VTEP)
interface nve1
  source-interface loopback0           ! IP-адрес на loopback0 будет использоваться как VTEP Source IP
  member vni 10100                    ! Например, VLAN 10 привязываем к VNI 10100
    mcast-group 239.1.1.1             ! Multicast-адрес для флуда и обучения

! Привязываем VLAN 10 к VNI 10100
vlan 10
  vn-segment 10100

```
На коммутаторе Nexus B аналогично:
```
feature nv overlay
feature vn-segment-vlan-based

interface nve1
  source-interface loopback0
  member vni 10100
    mcast-group 239.1.1.1

vlan 10
  vn-segment 10100

```

Таким образом VLAN 10 на обеих сторонах «связан» VNI 10100. Трафик между устройствами в VLAN 10 будет инкапсулироваться в VXLAN, «разливаясь» через мультикаст-группу. Понятно, что в реальной сети ещё надо добавить маршрутизацию, чтобы loopback0 на каждом коммутаторе мог достичь друг друга через IP-сеть, а также настроить PIM/IGMP, чтобы корректно работала мультикаст-группа.

2. Пример на Linux (используя ip-link)
Предположим, у нас есть два Linux-сервера с ядром, поддерживающим VXLAN:

```
# На первом сервере (10.10.10.1/24 - interface eth0):

# Создаём интерфейс vxlan10, указываем ID сегмента (VNI=10100), multicast-адрес 239.1.1.1 и порт 4789 (дефолт)
ip link add vxlan10 type vxlan id 10100 group 239.1.1.1 dev eth0 dstport 4789

# Поднимаем интерфейс
ip link set vxlan10 up

# Создаём bridge и добавляем в него vxlan10 и, скажем, внутренний интерфейс eth1, где «сидят» хосты
brctl addbr br10
brctl addif br10 eth1
brctl addif br10 vxlan10
ip link set br10 up

```
На втором сервере (10.10.10.2/24) делаем то же самое, указывая тот же VNI и тот же multicast group. В результате устройства, подключённые к eth1 на обоих серверах, оказываются в одном «виртуальном» L2-сегменте поверх IP-связности между этими серверами.

## Пример настройки VXLAN с EVPN (BGP EVPN)
Чтобы раскрыть «умную» сторону VXLAN, можно воспользоваться EVPN — тогда нужно настроить BGP (с поддержкой AFI/SAFI l2vpn evpn) и у каждого коммутатора будет единая система для обмена MAC/IP записями.
На Cisco (Nexus) или Arista (пример упрощённого фрагмента)
Включаем нужные фичи:

```
! Включаем нужные фичи:

feature bgp
feature nv overlay
feature vn-segment-vlan-based
feature evpn

!Создаём Loopback-интерфейс для VTEP:

interface loopback0
  ip address 10.0.0.1/32

!Настраиваем BGP с AF EVPN:

router bgp 65001
  router-id 10.0.0.1
  neighbor 10.0.0.2 remote-as 65001
  !
  address-family l2vpn evpn
    send-community extended
    route-reflector-client  (если этот свитч будет РР, зависит от дизайна)
    advertise l2vpn evpn

!Настраиваем NVE-интерфейс:

interface nve1
  source-interface loopback0
  member vni 10100
    ingress-replication protocol bgp   ! Вместо multicast указываем, что будем использовать BGP EVPN
  exit

!Привязка VLAN к VNI (VLAN-based или VLAN-aware bundle — зависит от дизайна):

vlan 10
  vn-segment 10100

```

Когда все участники (Leaf-коммутаторы) в одной AS (или нескольких, если это меж-AS EVPN) настроены таким образом, они обмениваются EVPN-маршрутами (типов 2, 3, 5 и т.д. в зависимости от необходимости) и автоматически узнают, где какой MAC-адрес «подвешен», какие IP-адреса находятся за каким VTEP, где включать ARP suppression и т.д. Это решает проблему «флуда» и избыточности при классической VXLAN+Multicast-схеме.

## Итоги

* VXLAN — механизм инкапсуляции L2-трафика в L3/UDP-пакеты. Обеспечивает гибкость, масштабирование и изоляцию.
* EVPN — протокол динамического обмена MAC/IP (и другой сервисной информации) на базе BGP, позволяющий централизованно (через Control Plane) управлять VXLAN-оверлеем.
* VXLAN в ЦОД даёт возможность «растягивать» логические L2 по IP-ядру, лучше масштабироваться, эффективно использовать маршрутизацию (ECMP) и одновременно предоставлять виртуальным машинам «локальную» L2-сеть.
* Существуют различные схемы настройки:
* * «VXLAN flood & learn» (через multicast или head-end replication), где все VTEP’ы сами обмениваются трафиком и MAC-таблицами.
* * «VXLAN EVPN» (используя BGP EVPN), когда все MAC-адреса, ARP-записи, VNI, шлюзы и т.д. синхронизируются автоматически через BGP — это более «продвинутая» и хорошо масштабируемая архитектура для больших ЦОД.
Таким образом, если требуется просто «потестить» overlay или организовать относительно простую схему, можно настроить классический VXLAN с мультикаст-группой. Но если встаёт задача уровня «полноценной фабрики» в большом ЦОД — практически всегда выбирают VXLAN + EVPN, чтобы централизованно управлять топологией и избавиться от ручной прописки.

![image](https://github.com/user-attachments/assets/e36fb8d9-fc6e-4424-af12-bca400acf744)

![image](https://github.com/user-attachments/assets/c37b819f-fa65-42dd-ad0f-5a687725567a)

![image](https://github.com/user-attachments/assets/42de1e9b-a78c-43b6-bfdd-c5b17fd6181f)

![image](https://github.com/user-attachments/assets/67e67efb-ebef-4067-bf56-aab30bda3e02)

![image](https://github.com/user-attachments/assets/d993b7ab-a494-44a6-94a4-f8507bbfc076)

![image](https://github.com/user-attachments/assets/f292ea2d-486a-4388-9aa2-6b63e3bd365c)

![image](https://github.com/user-attachments/assets/78c6051f-ab8b-433e-bd91-0987c0d66a94)


![image](https://github.com/user-attachments/assets/bc0d931c-92e4-4a46-b42e-f9ca83765d17)



