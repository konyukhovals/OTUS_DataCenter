# VRF Leaking и BGP

![image](https://github.com/user-attachments/assets/dea09b19-a80e-4059-8bce-c416c024fd57)

![image](https://github.com/user-attachments/assets/36fdbf87-39c8-418e-a91b-20cc71d0bfbf)

![image](https://github.com/user-attachments/assets/b2c2f624-f684-4b9c-9916-aa10d2959a00)

![image](https://github.com/user-attachments/assets/f55dad0b-3ba3-439c-b790-f2709ffef6e4)

![image](https://github.com/user-attachments/assets/24f781f2-beee-4772-8bc0-ec9857797884)

## Что такое VRF leaking

VRF leaking (иногда говорят «маршрутизация между VRF», «route leaking» и т.п.) — это механизм, позволяющий «делиться» маршрутами между разными VRF (Virtual Routing and Forwarding).
В стандартном случае каждый VRF — это отдельная «виртуальная» (логическая) таблица маршрутизации, изолированная от других VRF. Такая изоляция нужна для:
* Разделения трафика разных клиентов (особенно в MPLS VPN);
* Разделения сетей разных сервисов в рамках одного оператора/предприятия;
* Мультиарендности (multi-tenant) в дата-центрах;
* Сегментации сети для повышения безопасности.

Но бывают случаи, когда необходимо, чтобы один VRF «видел» маршруты другого. К примеру:
* Существует общий сервисный VRF (DNS, NTP, AD, интернет-шлюз), к которому должны обращаться разные VRF.
* Нужно выборочно «пробросить» некоторые подсети между VRF (при этом остальные остаются изолированными).

Чтобы это сделать, используется механизм VRF leaking — «протекание» (leak) маршрутов из одного VRF в другой. В MPLS L3VPN (BGP/MPLS VPN) это делается через route-target import/export, а в классических конфигурациях Cisco IOS — с помощью статических маршрутов (команда ip route vrf ...), route-map, BGP/OSPF «между VRF» и т.д.

## Для чего нужен VRF leaking

* Общий сервисный VRF. Допустим, у вас есть VRF SERVICES с ресурсами, к которым должны иметь доступ другие VRF (например, клиенты).
* Выборочный доступ. Нужно, чтобы из одного VRF были доступны только определённые сети другого VRF.
* Упрощение сети. Не всегда удобно «выводить» трафик наружу или на отдельное устройство, если можно организовать обмен маршрутами внутри одного роутера/коммутатора.

### Основные способы реализации

1. Route-target (в средах MPLS L3VPN)

В больших сетях с MPLS L3VPN маршруты «изолируются» VRF-ами, а обмен маршрутами между VRF организуется через RT (route-target):
* Export — какие метки (RT) назначаются маршрутам из VRF.
* Import — какие метки (RT) VRF «подтягивает» к себе.

Пример (упрощённый):
```
ip vrf CLIENT-A
 rd 65000:100
 route-target export 65000:100
 route-target import 65000:900

ip vrf SERVICES
 rd 65000:900
 route-target export 65000:900
 route-target import 65000:100
```

Таким образом, CLIENT-A импортирует маршруты, помеченные RT 65000:900 (то есть маршруты из VRF SERVICES), а SERVICES импортирует маршруты, помеченные RT 65000:100 (то есть из CLIENT-A). Можно настроить и односторонний доступ, если нужно.

2. Статические маршруты (ip route vrf …)

В «чистом» IOS (без MPLS) часто применяют статические маршруты, позволяющие «поделиться» маршрутами между VRF. Пример (упрощённый), когда нужно, чтобы VRF BLUE видел сеть 10.10.20.0/24 из VRF RED, и наоборот:

```
! Из BLUE в RED:
ip route vrf BLUE 10.10.20.0 255.255.255.0 10.10.10.254 global

! Из RED в BLUE:
ip route vrf RED 10.10.10.0 255.255.255.0 10.10.20.254 global
```

При этом в качестве next-hop указываем либо адрес другого VRF, либо интерфейс (в более новых версиях IOS-XE можно и так, и так). Важно аккуратно настроить маршруты в обе стороны.

3. Протоколы динамической маршрутизации (BGP/OSPF/EIGRP) «между VRF»
Можно поднять BGP или другой протокол между VRF одного и того же устройства («сам с собой»). Через route-map, фильтры, ACL определять, какие сети будут «протекать» в другой VRF. Это более редкий способ, иногда используется в особых случаях.

4. Команды import/export (IOS-XE)
В некоторых реализациях (IOS-XE) есть возможность прописывать в секции ip vrf команды наподобие:

```
ip vrf BLUE
 ...
 address-family ipv4
  import ipv4 unicast route-policy MY_RM
  export ipv4 unicast route-policy MY_RM

```

Либо import ipv4 unicast from VRF RED, что позволяет «выбрать» конкретные сети из VRF RED. Но это, по сути, более современный аналог идеи с RT или со статическими маршрутами.

## VRF leaking в CLOS

В CLOS-сетях (leaf-spine архитектура), особенно в больших дата-центрах, VRF используется для мультиарендности (tenant) или сегментации внутри одного арендатора. Тогда leaking необходим, когда разные VRF должны «видеть» общий сервис (интернет, DNS, мониторинг и т.д.).
* В EVPN/VXLAN (часто в современных DC) leaking реализуется через import/export RT (похожим образом, как в MPLS).
* В классической L3 CLOS без EVPN может быть «центральный» роутер (border / service leaf), где настроен BGP, и там делается взаимный обмен маршрутами между VRF с нужными RT или статикой.

## VRF leaking — механизм, позволяющий выборочно пробрасывать маршруты между VRF, которые изначально изолированы друг от друга.

Применяется для доступа к общим службам, интерент-шлюзу, взаимных сервисов и т.д.

Способы:
* MPLS L3VPN: через route-target import/export;
* Статические ip route vrf ...: для небольших сценариев;
* Динамические протоколы (BGP, OSPF и т.п.): когда нужно гибко управлять маршрутами;
* IOS-XE import/export: более современные команды, похожие на RT-модель.

В контексте CLOS (leaf-spine) VRF leaking актуален при необходимости предоставлять общие сервисы нескольким VRF.
Таким образом, VRF leaking — это контролируемый обмен маршрутами, позволяющий «пробросить» нужные префиксы между виртуальными таблицами маршрутизации.



# Что такое border leaf и зачем он нужен

В CLOS-сетях (leaf-spine) каждый leaf (лист) обычно подключён к нескольким spine (корневым) коммутаторам/маршрутизаторам, образуя полно-мешевую или частично-мешевую структуру. Узлы (серверы, виртуальные машины и т.п.) подключаются к leaf-у. Внутри такого фабрика (fabric) — полностью сеть Layer 3 (L3) или же L2-over-L3 (EVPN/VXLAN, etc.).
Однако необходимо, чтобы какие-то устройства (или сети) «снаружи» тоже могли взаимодействовать с этим фабриком. 

Например:
* Подключение к корпоративной WAN/мане/интернету;
* Доступ к другим дата-центрам;
* Связь с традиционной сетью (Legacy network);
* Подключение к внешним сервисам (SaaS, CDN и т.д.).

Для этого в архитектуре CLOS часто выделяют border leaf — специальный (или один из обычных, но с расширенным функционалом) leaf, который предоставляет «шлюз» изнутри фабрика наружу и обратно. Фактически, border leaf — это точка стыка (присоединения) внешних сетей к Spine-Leaf фабрику.

Основные задачи border leaf:
* Маршрутизация наружу: обменивается маршрутами с внешними маршрутизаторами (eBGP, OSPF, статические маршруты и т.д.).
* Поддержка VRF/tenant: если внутри CLOS используется мультиарендная среда (несколько VRF или VNI в EVPN/VXLAN), border leaf должен «леакать» (пробрасывать) нужные маршруты наружу или в другие VRF/зоны.
* NAT / Firewall / Устройства безопасности (по желанию): иногда именно на border leaf (или за ним) размещают функции NAT, Firewall, IPS/IDS и т.п.
* L2-extend или L3-extend (в зависимости от дизайна): если нужно протянуть VLAN (или VXLAN) наружу, border leaf может инкапсулировать/декапсулировать соответствующий трафик.

## Пример конфигурации (упрощённый)
Ниже — пример (абстрактный, не «прямо копировать-вставить») для устройства Cisco (например, NX-OS или IOS-XE в режиме data center). Покажем схему, где:

* Border Leaf подключен к Spine внутри фабрика (через IP-интерфейсы p2p).
* Border Leaf имеет внешнее подключение, скажем, через интерфейс Ethernet1/49 к провайдеру или корпоративной сети.
* Используется BGP как внутри (iBGP/EVPN с spine-ами), так и снаружи (eBGP с провайдером).
* Есть несколько VRF, например:

* * Tenant-A (VNI 10010)

* * Tenant-B (VNI 10020)

* * common-services (VNI 10050)

* * Border Leaf экспортирует/импортирует маршруты между фабриком (через EVPN/BGP) и внешним BGP (eBGP), делая VRF leaking, если нужно.

1. Определяем VRF и VLAN/VNI (если EVPN)

```
! Пример, задаём VRF
vrf context Tenant-A
  vni 10010

vrf context Tenant-B
  vni 10020

vrf context common-services
  vni 10050

```
(В MPLS-сети вместо этого могли быть ip vrf + RD/RT.)

2. Интерфейсы внутри фабрика (Leaf-Spine)
Допустим, Spine имеет адреса 10.0.0.1, 10.0.0.2, а Border Leaf — 10.0.0.11 и 10.0.0.12 на разных интерфейсах. Сами интерфейсы могут быть Ethernet1/1, Ethernet1/2 и т.д. (зависит от физической схемы).

```
interface Ethernet1/1
  description Uplink to Spine1
  no switchport
  ip address 10.0.0.11/31
  ip router ospf 1 area 0  ! или BGP Unnumbered, или статические маршруты – зависит от дизайна

interface Ethernet1/2
  description Uplink to Spine2
  no switchport
  ip address 10.0.0.13/31
  ip router ospf 1 area 0

```
В EVPN VXLAN дизайне чаще используют loopback для BGP source, и p2p ссылки на Spine только для IP reachability.

3. Интерфейс наружу
Пусть внешний провайдер/маршрутизатор подключён на Ethernet1/49. Для простоты пример — один VRF common-services «виден» снаружи. Тогда мы делаем так:

```
interface Ethernet1/49
  vrf member common-services
  description Uplink to WAN
  ip address 192.168.100.2/30

```
(Если у нас несколько VRF, в NX-OS можно использовать sub-interface, или прямые VLAN для каждой VRF, или же внешнее Q-in-Q, — вариантов много.)

4. Настройки BGP внутри (с Spine) и снаружи (с провайдером)
Предположим, мы используем eBGP c провайдером (AS 65010), а внутри CLOS — iBGP (AS 65000) или же EVPN BGP. Упрощённо:

```
router bgp 65000
  router-id 10.255.255.1
  !
  ! Это наш «фабричный» BGP контекст, который поднимает EVPN или обычный iBGP со Spine:
  neighbor 10.0.0.1 remote-as 65000
  neighbor 10.0.0.1 update-source Ethernet1/1
  address-family ipv4 unicast
    network 10.0.0.0/31
    ...
  !
  ! Допустим, EVPN для «коридора» VXLAN:
  address-family l2vpn evpn
    send-community extended
    advertise-all-vni
  !
  ! Поднимаем контекст VRF, который будет «говорить» BGP снаружи:
  vrf common-services
    rd 65000:50
    route-target import 65000:50
    route-target export 65000:50
    ! eBGP с провайдером:
    neighbor 192.168.100.1 remote-as 65010
      address-family ipv4 unicast
        send-community extended
        ! Здесь можем импортировать default route от провайдера, а отдавать ему нужные подсети
        ! Например, network 0.0.0.0/0 (или redistribute static default-originate), и т.д.

```

Таким образом:

* vrf common-services «подтягивает» маршруты из BGP peer 192.168.100.1 (провайдер).
* Внутри фабрика border leaf обменивается маршрутами (EVPN или L3) с Spine.

5. VRF leaking (при необходимости)
Если у нас есть Tenant-A и Tenant-B, которым нужен доступ к интернету или общим сервисам, на border leaf настраиваем leaking между их VRF и common-services (или «INTERNET» VRF). В EVPN это делается через import/export RT (route-target) или через дополнительные команды import l3 <другой-VRF>, в зависимости от ОС.
Упрощённый пример (NX-OS, где используются RT community):

```
vrf context Tenant-A
  rd 65000:10
  route-target export 65000:10
  route-target import 65000:10
  ! Если нужно чтобы Tenant-A видел default route из common-services:
  route-target import 65000:50
  ! И, возможно, экспортируем некоторые сети в common-services, если нужен трафик обратно.
  route-target export 65000:50 map FILTER-OUT

vrf context common-services
  rd 65000:50
  route-target import 65000:50
  route-target export 65000:50
  ! Или импортируем и RT 65000:10 (если нужен обратный маршрут от Tenant-A).

```
При более сложных сценариях используют route-map/политики. Главное — определять, какие сети «протекают» из одного VRF в другой.

6. Фильтрация, ACL, безопасность
На border leaf обычно настраивают дополнительные ACL, control-plane политику, фильтрацию BGP (какие префиксы принимает и анонсирует наружу), возможно NAT (в случае классического IOS-XE) или интеграцию с внешним firewall (в случае NX-OS часто выносят на отдельное устройство).

## Итог

1. Border leaf в CLOS-сети — это узел, через который фабрик (leaf-spine) получает/отдаёт трафик во внешние сети (WAN/интернет/другие DC).
2. Он заимодействует с Spine внутри фабрика (iBGP/OSPF/IS-IS/EVPN) и имеет eBGP (или другой протокол) с внешними маршрутизаторами.
3. В мультиарендной (multi-tenant) архитектуре border leaf занимается VRF leaking (import/export route-target), чтобы нужные VRF имели доступ наружу, а остальные оставались изолированными.
4. Конфигурация включает:
* Создание VRF;
* Настройку интерфейсов (внутрь фабрика и наружу);
* BGP (или другой протокол) внутри (AS 65000) и снаружи (eBGP к провайдеру);
* Опционально: NAT/Firewall/ACL (в зависимости от требований безопасности).

Таким образом, border leaf играет роль «пограничного» маршрутизатора для CLOS-фабрика, соединяя внутренние «виртуальные» сети/VRF с внешними маршрутами и обеспечивая политику доступа и безопасности.

# VNI 

### (VXLAN Network Identifier) — это 24-битный идентификатор «виртуальной сети» в протоколе VXLAN (Virtual eXtensible LAN).

Когда в современном дата-центре (или другой L3-сети) нужно передавать L2-сегменты поверх IP-сети (так называемый overlay), используют VXLAN-инкапсуляцию: Ethernet-кадры «упаковываются» в UDP (иногда говорят “MAC-in-UDP”) и пересылаются по сети Layer 3.
* VNI отвечает за то, чтобы разные «виртуальные сети» (broadcast-домены, VLAN'ы и т.п.) были логически изолированы друг от друга, даже если физическая инфраструктура общая.
* По аналогии с VLAN ID (который 12-битный и ограничен 4094 VLAN’ами), VXLAN позволяет иметь 24-битный VNI, давая возможность создавать до 16 миллионов (2^24) изолированных виртуальных сегментов.
* Каждый VNI обычно ассоциируется с конкретным VRF (Virtual Routing and Forwarding) и/или VLAN в фреймворке EVPN/VXLAN (в зависимости от того, говорим ли мы о L2 VNI или L3 VNI).

Главная идея:
1. Узлы в одной виртуальной сети (один и тот же VNI) могут взаимодействовать между собой на 2-м уровне (словно в одной VLAN), даже если они физически подключены к разным коммутаторам leaf.
2. Трафик между разными VNI изолирован по умолчанию и требует маршрутизации (L3) или механизма «VRF leaking», если нужен доступ из одного сегмента в другой.
Таким образом, VNI — это «ключ» (идентификатор) к конкретному логическому сегменту сети при использовании VXLAN.

# RT/RD

## 1. Что такое RD (Route Distinguisher)
Route Distinguisher (RD) — это 8-байтовый идентификатор (обычно записывается в формате ASN:номер или IP-адрес:номер), который делает маршруты в рамках MPLS/VPN уникальными.

В классической IP-маршрутизации (без VRF) у нас есть глобальная таблица маршрутов, и каждый маршрут идентифицируется по «IP prefix + маска». Но если у нас есть два VRF, содержащие одинаковые IP-подсети (например, 10.10.10.0/24), без дополнительных механизмов в BGP их невозможно различать.
RD добавляется к префиксу как «префикс пространства имен», делая итоговую запись уникальной:

* Пример: если в VRF_A стоит RD 65000:100, а в VRF_B RD 65000:200, то маршрут 10.10.10.0/24 внутри VRF_A будет во внешнем представлении «65000:100:10.10.10.0/24», а во VRF_B — «65000:200:10.10.10.0/24».

Таким образом, RD не определяет, кто будет видеть эти маршруты (это задача RT), а лишь «дополняет» сам маршрут, чтобы в глобальном BGP (MP-BGP) можно было различать одинаковые IP-сети из разных VRF.

## 2. Что такое RT (Route Target)
Route Target (RT) — это расширенное BGP-сообщество (extended community), обычно также пишется как ASN:номер. Но его назначение — управление импортом/экспортом маршрутов в разные VRF.
* Export RT: Когда VRF «отправляет» свои маршруты в MP-BGP, он «метит» их определённым RT. Например, route-target export 65000:100.
* Import RT: Чтобы VRF «получил» (импортировал) нужные маршруты, он должен «слушать» тот же RT. Например, route-target import 65000:100.

Таким образом, RT — это своего рода «ярлык членства». VRF экспортирует маршруты со своими RT, и импортирует маршруты, у которых RT совпадает с его списком import.
*Именно RT фактически определяет, каким VRF какие маршруты доступны, а RD лишь различает маршруты «внутри» BGP.

## 3. MP-BGP (Multiprotocol BGP)
Чтобы MPLS L3VPN или EVPN работали, мы используем MP-BGP (Multiprotocol BGP) — расширение протокола BGP, позволяющее передавать не только IPv4 unicast, но и иные «адресные семейства» (Address Family), например:

* vpnv4, vpnv6 (для MPLS L3VPN);
* l2vpn evpn (для EVPN/VXLAN или EVPN/MPLS);
* и т.д.

### 3.1. Как RD/RT встраиваются в MP-BGP
* RD становится частью маршрута в NLRI (Network Layer Reachability Information), например: (RD, IPv4-prefix).
* RT передаётся внутри атрибутов BGP (Extended Communities).
* MP-BGP роут-рефлекторы (RR) или BGP-соседи (PE) распространяют эти расширенные маршруты (vpnv4/evpn и т.д.).
* На принимающей стороне (другой PE или Leaf) смотрят: «Какие RT я импортирую?». Если RT маршрута совпадает, маршрут попадает в соответствующий VRF.

## 4. Применение в сетях MPLS
### 4.1. MPLS L3VPN (классическая провайдерская схема)
* Каждый PE (Provider Edge) имеет несколько VRF (Client1, Client2, …).

* У VRF:

* * rd <something> (например, 65000:101).

* * route-target export <RT_out>, route-target import <RT_in>.

* MP-BGP (vpnv4 AF) между PE (через P/Route Reflector) распространяет маршруты.

* Благодаря RT, клиентские VRF «видят» только маршруты своих VPN, а не чужие.

### 4.2. MPLS + MP-BGP в контексте DC
Хотя MPLS чаще ассоциируется с провайдерской WAN, в некоторых больших дата-центрах применяется MPLS внутри CLOS — называется «MPLS Fabric». RD/RT работают по тому же принципу, только Spine-Leaf инфраструктура (Spine = P/RR, Leaf = PE). Это позволяет иметь очень много VRF внутри дата-центра, при этом используя знакомые механизмы MPLS L3VPN.

## 5. Применение в CLOS-сетях (EVPN/VXLAN)
В современных DC CLOS вместо «MPLS VPN» нередко используют EVPN/VXLAN. Но логика RD/RT остается схожей:
* RD назначается при создании VRF (для L3 VNI) или при создании L2 VNI (в случае BD - Bridge Domain).
* Route Target указывает, какие маршруты (MAC/IP) или префиксы будут импортироваться/экспортироваться другими Leaf.
* Протокол — MP-BGP EVPN (адресное семейство l2vpn evpn).
* В таком случае RD присутствует в EVPN NLRI (например, Type-2, Type-5 маршруты), чтобы «отличать» одинаковые IP внутри разных VRF/tenant.
* RT (часто говорят «EVPN RT») определяет, какая VXLAN-сеть (VNI) будет «видеть» данные маршруты.
Итог тот же: RD — уникальность маршрутов, RT — контроль доступа/импорта.

### 5.1. Пример (Cisco, EVPN)

```
vrf context Tenant-A
  rd 65000:100
  route-target import 65000:100
  route-target export 65000:100
  vni 10100
```

Здесь:
* rd 65000:100 — RD для уникальности.
* route-target import/export 65000:100 — RT, который «сшивает» EVPN.
* vni 10100 — VXLAN Network Identifier для данного VRF (L3 VNI).

Все Leaf-узлы, имеющие этот VRF Tenant-A с RT 65000:100, будут обмениваться маршрутами.

## 6. Взаимосвязь с архитектурой CLOS
### 6.1. Leaf-Spine с BGP Route Reflectors
Часто Spine-коммутаторы (или выделенные RR) являются BGP Route Reflector’ами, а Leaf-коммутаторы — клиентами (RR clients).
* Leaf поднимает MP-BGP с каждым Spine (iBGP).
* Размещает в нём маршруты своих локальных VRF (с RT, RD).
* Spine как RR просто ретранслирует их другим Leaf.

### 6.2. Многотенантность, Segment Routing, EVPN
В больших DC нужен multi-tenancy (когда многие VRF/tenant), плюс быстрая конвергенция и автоматическое распространение маршрутов. RD/RT позволяют масштабировать и изолировать много логических сетей в одном «fabric».
Кратко
* RD (Route Distinguisher) — делает маршруты уникальными, добавляя «метку» к IP-префиксу.
* RT (Route Target) — определяет, какие VRF импортируют или экспортируют данные маршруты (механизм фильтрации/распределения).
* MP-BGP (Multiprotocol BGP) — расширение BGP, поддерживающее различные Address Family (vpnv4, l2vpn evpn и т.д.) и позволяющее перенести внутри BGP «VPN-маршруты» (с RD/RT).
* В MPLS L3VPN классически задействуют RD/RT в рамках провайдерской сети (PE/P/CE). В EVPN/VXLAN (часто в CLOS-сетях) — аналогично используют RD/RT, но в формате EVPN (l2vpn evpn).
* В CLOS Leaf-Spine топологии, RD/RT — стандартный механизм для поддержки множества VRF (tenant), их изоляции, а также для selective leaking (import/export).
Таким образом, RD и RT — это ключевые строительные блоки MPLS VPN и EVPN VPN, а в CLOS-сетях они применяются для организации мультиарендности, сегментации и масштабируемой маршрутизации внутри фабрика.
